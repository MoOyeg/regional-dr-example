---
# =============================================================================
# NetObserv Setup via ACM Policy
# =============================================================================
# This playbook:
# 1. Provisions S3 buckets per cluster for Loki storage (Play 1)
# 2. Creates an ACM Policy on the hub that deploys Loki, NetObserv operators,
#    LokiStack with S3 backend, and FlowCollector to managed clusters (Play 2)
#
# The Policy uses hub-side templates ({{hub fromSecret hub}}) to inject
# per-cluster S3 credentials and bucket configuration.
#
# Prerequisites:
# - ACM installed on hub (run ./ansible-runner.sh operators first)
# - Spoke clusters imported (run ./ansible-runner.sh import first)
# - AWS credentials with S3 permissions
# - netobserv: true in cluster inventory host_vars
# =============================================================================

# =============================================================================
# Play 1: Provision S3 buckets for Loki storage
# =============================================================================
- name: "Play 1: Provision S3 buckets for Loki storage"
  hosts: openshift_clusters
  gather_facts: false

  vars:
    artifacts_dir: "{{ playbook_dir }}/artifacts"

  pre_tasks:
    - name: Skip clusters without netobserv enabled
      meta: end_host
      when: netobserv is not defined or not netobserv | bool

    - name: Validate kubeconfig exists
      stat:
        path: "{{ artifacts_dir }}/{{ cluster_name }}/kubeconfig"
      register: kubeconfig_stat
      delegate_to: localhost

    - name: End host if kubeconfig missing
      meta: end_host
      when: not kubeconfig_stat.stat.exists

    - name: Retrieve AWS credentials
      set_fact:
        aws_access_key: "{{ lookup('env', 'AWS_ACCESS_KEY_ID_' + (aws_credential_set | string)) }}"
        aws_secret_key: "{{ lookup('env', 'AWS_SECRET_ACCESS_KEY_' + (aws_credential_set | string)) }}"
        aws_deploy_region: "{{ lookup('env', 'AWS_REGION_' + (aws_credential_set | string)) | default(aws_region, true) }}"

    - name: Validate AWS credentials are available
      assert:
        that:
          - aws_access_key | length > 0
          - aws_secret_key | length > 0
        fail_msg: |
          AWS credentials not found for credential set {{ aws_credential_set }}
          Set: export AWS_ACCESS_KEY_ID_{{ aws_credential_set }}="..."
               export AWS_SECRET_ACCESS_KEY_{{ aws_credential_set }}="..."

    - name: Check if S3 bucket already provisioned
      stat:
        path: "{{ artifacts_dir }}/{{ cluster_name }}/s3-bucket-name"
      register: s3_bucket_file
      delegate_to: localhost

    - name: Read existing S3 bucket name
      shell: cat {{ artifacts_dir }}/{{ cluster_name }}/s3-bucket-name
      delegate_to: localhost
      register: existing_s3_bucket
      changed_when: false
      when: s3_bucket_file.stat.exists

    - name: Set existing bucket fact
      set_fact:
        s3_bucket_name: "{{ existing_s3_bucket.stdout | trim }}"
        skip_bucket_creation: true
      when: s3_bucket_file.stat.exists

    - name: Set skip flag when bucket does not exist
      set_fact:
        skip_bucket_creation: false
      when: not s3_bucket_file.stat.exists

  tasks:
    # =========================================================================
    # Create S3 bucket for Loki backend
    # =========================================================================
    - name: Generate timestamp for S3 bucket name
      shell: date +%s
      delegate_to: localhost
      register: timestamp_result
      changed_when: false
      when: not skip_bucket_creation

    - name: Set S3 bucket name
      set_fact:
        s3_bucket_name: "netobserv-loki-{{ cluster_name }}-{{ aws_deploy_region }}-{{ timestamp_result.stdout }}"
      when: not skip_bucket_creation

    - name: Create S3 bucket for Loki storage
      shell: |
        AWS_ACCESS_KEY_ID="{{ aws_access_key }}" \
        AWS_SECRET_ACCESS_KEY="{{ aws_secret_key }}" \
        aws s3api create-bucket \
          --bucket "{{ s3_bucket_name }}" \
          --region "{{ aws_deploy_region }}" \
          {% if aws_deploy_region != 'us-east-1' %}--create-bucket-configuration LocationConstraint={{ aws_deploy_region }}{% endif %}

      delegate_to: localhost
      when: not skip_bucket_creation

    - name: Tag S3 bucket
      shell: |
        AWS_ACCESS_KEY_ID="{{ aws_access_key }}" \
        AWS_SECRET_ACCESS_KEY="{{ aws_secret_key }}" \
        aws s3api put-bucket-tagging \
          --bucket "{{ s3_bucket_name }}" \
          --region "{{ aws_deploy_region }}" \
          --tagging 'TagSet=[{Key=cluster,Value={{ cluster_name }}},{Key=managed-by,Value=netobserv}]'
      delegate_to: localhost
      retries: 3
      delay: 5
      when: not skip_bucket_creation

    - name: Enable versioning on S3 bucket
      shell: |
        AWS_ACCESS_KEY_ID="{{ aws_access_key }}" \
        AWS_SECRET_ACCESS_KEY="{{ aws_secret_key }}" \
        aws s3api put-bucket-versioning \
          --bucket "{{ s3_bucket_name }}" \
          --region "{{ aws_deploy_region }}" \
          --versioning-configuration Status=Enabled
      delegate_to: localhost
      retries: 3
      delay: 5
      when: not skip_bucket_creation

    - name: Save S3 bucket name to artifacts
      copy:
        content: "{{ s3_bucket_name }}"
        dest: "{{ artifacts_dir }}/{{ cluster_name }}/s3-bucket-name"
      delegate_to: localhost
      when: not skip_bucket_creation

    - name: Display S3 bucket status
      debug:
        msg: |
          S3 Bucket for {{ cluster_name }}:
          {% if skip_bucket_creation %}
          Already exists: {{ s3_bucket_name }}
          {% else %}
          Created: {{ s3_bucket_name }}
          Region: {{ aws_deploy_region }}
          {% endif %}

# =============================================================================
# Play 2: Configure NetObserv via ACM Policy
# =============================================================================
- name: "Play 2: Configure NetObserv via ACM Policy"
  hosts: openshift_clusters
  gather_facts: false

  vars:
    artifacts_dir: "{{ playbook_dir }}/artifacts"
    policy_name: "netobserv-policy"
    policy_namespace: "netobserv-policy"
    placement_name: "netobserv-placement"

  pre_tasks:
    - name: Skip non-hub clusters
      meta: end_host
      when: cluster_role | default('spoke') != 'hub'

    - name: Validate kubeconfig exists
      stat:
        path: "{{ artifacts_dir }}/{{ cluster_name }}/kubeconfig"
      register: kubeconfig_stat
      delegate_to: localhost

    - name: Fail if kubeconfig missing
      fail:
        msg: "Kubeconfig not found. Deploy the hub cluster first."
      when: not kubeconfig_stat.stat.exists

    - name: Verify cluster connectivity
      shell: oc whoami
      environment:
        KUBECONFIG: "{{ artifacts_dir }}/{{ cluster_name }}/kubeconfig"
      delegate_to: localhost
      changed_when: false

    - name: Check ACM CSV is Succeeded
      shell: |
        oc get csv -n open-cluster-management \
          -o jsonpath='{.items[?(@.spec.displayName=="Advanced Cluster Management for Kubernetes")].status.phase}'
      environment:
        KUBECONFIG: "{{ artifacts_dir }}/{{ cluster_name }}/kubeconfig"
      delegate_to: localhost
      register: acm_csv_status
      changed_when: false

    - name: Fail if ACM is not installed
      fail:
        msg: >-
          ACM operator is not in Succeeded state (got: '{{ acm_csv_status.stdout }}').
          Run './ansible-runner.sh operators' first.
      when: "'Succeeded' not in acm_csv_status.stdout"

    - name: Build list of spoke clusters with netobserv enabled
      set_fact:
        netobserv_clusters: "{{ groups['openshift_clusters'] |
          map('extract', hostvars) |
          selectattr('netobserv', 'defined') |
          selectattr('netobserv', 'equalto', true) |
          map(attribute='cluster_name') |
          list }}"

    - name: Display netobserv clusters
      debug:
        msg: "NetObserv will be configured on: {{ netobserv_clusters | join(', ') }}"

    - name: End play if no clusters have netobserv enabled
      meta: end_play
      when: netobserv_clusters | length == 0

  tasks:
    # =========================================================================
    # Label managed clusters for placement
    # =========================================================================
    - name: Build managedcluster name mapping
      set_fact:
        managedcluster_names: >-
          {
          {% for spoke_cluster in netobserv_clusters %}
          {% set spoke_vars = hostvars[spoke_cluster] %}
          {% if spoke_vars.managedcluster_name is defined %}
          "{{ spoke_cluster }}": "{{ spoke_vars.managedcluster_name }}"
          {% elif spoke_vars.cluster_role | default('spoke') == 'hub' %}
          "{{ spoke_cluster }}": "local-cluster"
          {% else %}
          "{{ spoke_cluster }}": "{{ spoke_cluster }}"
          {% endif %}
          {% if not loop.last %},{% endif %}
          {% endfor %}
          }

    - name: Display managedcluster mapping
      debug:
        msg: |
          ManagedCluster Name Mapping:
          {% for cluster, mc_name in managedcluster_names.items() %}
          - {{ cluster }} -> {{ mc_name }}
          {% endfor %}

    - name: Label managed clusters with netobserv=true
      shell: |
        oc label managedcluster {{ managedcluster_names[item] }} netobserv=true --overwrite
      environment:
        KUBECONFIG: "{{ artifacts_dir }}/{{ cluster_name }}/kubeconfig"
      delegate_to: localhost
      loop: "{{ netobserv_clusters }}"
      changed_when: false

    # =========================================================================
    # Create policy namespace, ManagedClusterSetBinding, Placement, and PlacementBinding
    # =========================================================================
    - name: Create policy namespace
      shell: |
        oc apply -f - <<'EOF'
        apiVersion: v1
        kind: Namespace
        metadata:
          name: {{ policy_namespace }}
        EOF
      environment:
        KUBECONFIG: "{{ artifacts_dir }}/{{ cluster_name }}/kubeconfig"
      delegate_to: localhost

    - name: Bind global ManagedClusterSet to policy namespace
      shell: |
        oc apply -f - <<'EOF'
        apiVersion: cluster.open-cluster-management.io/v1beta2
        kind: ManagedClusterSetBinding
        metadata:
          name: global
          namespace: {{ policy_namespace }}
        spec:
          clusterSet: global
        EOF
      environment:
        KUBECONFIG: "{{ artifacts_dir }}/{{ cluster_name }}/kubeconfig"
      delegate_to: localhost

    - name: Create Placement for netobserv clusters
      shell: |
        oc apply -f - <<'EOF'
        apiVersion: cluster.open-cluster-management.io/v1beta1
        kind: Placement
        metadata:
          name: {{ placement_name }}
          namespace: {{ policy_namespace }}
        spec:
          clusterSets:
            - global
          predicates:
            - requiredClusterSelector:
                labelSelector:
                  matchLabels:
                    netobserv: "true"
        EOF
      environment:
        KUBECONFIG: "{{ artifacts_dir }}/{{ cluster_name }}/kubeconfig"
      delegate_to: localhost

    - name: Create PlacementBinding
      shell: |
        oc apply -f - <<'EOF'
        apiVersion: policy.open-cluster-management.io/v1
        kind: PlacementBinding
        metadata:
          name: {{ policy_name }}-binding
          namespace: {{ policy_namespace }}
        placementRef:
          apiGroup: cluster.open-cluster-management.io
          kind: Placement
          name: {{ placement_name }}
        subjects:
          - apiGroup: policy.open-cluster-management.io
            kind: Policy
            name: {{ policy_name }}
        EOF
      environment:
        KUBECONFIG: "{{ artifacts_dir }}/{{ cluster_name }}/kubeconfig"
      delegate_to: localhost

    # =========================================================================
    # Create hub-side per-cluster secrets for S3 credentials
    # =========================================================================
    - name: Read S3 bucket names from artifacts
      shell: cat {{ artifacts_dir }}/{{ item }}/s3-bucket-name
      delegate_to: localhost
      register: s3_bucket_results
      changed_when: false
      loop: "{{ netobserv_clusters }}"

    - name: Build per-cluster S3 credential info
      set_fact:
        cluster_s3_info: >-
          {{ cluster_s3_info | default([]) + [{
            'mc_name': managedcluster_names[item.item],
            'bucket_name': item.stdout | trim,
            'access_key': lookup('env', 'AWS_ACCESS_KEY_ID_' + (hostvars[item.item]['aws_credential_set'] | string)),
            'secret_key': lookup('env', 'AWS_SECRET_ACCESS_KEY_' + (hostvars[item.item]['aws_credential_set'] | string)),
            'region': lookup('env', 'AWS_REGION_' + (hostvars[item.item]['aws_credential_set'] | string)) | default(hostvars[item.item]['aws_region'], true)
          }] }}
      loop: "{{ s3_bucket_results.results }}"
      no_log: true

    - name: Display per-cluster S3 info (bucket names only)
      debug:
        msg: |
          Per-cluster S3 configuration:
          {% for info in cluster_s3_info %}
          - {{ info.mc_name }}: {{ info.bucket_name }} ({{ info.region }})
          {% endfor %}

    - name: Create netobserv-s3-creds secret per cluster in policy namespace
      shell: |
        oc apply -f - <<'EOF'
        apiVersion: v1
        kind: Secret
        metadata:
          name: netobserv-s3-creds-{{ item.mc_name }}
          namespace: {{ policy_namespace }}
        type: Opaque
        stringData:
          bucketname: "{{ item.bucket_name }}"
          endpoint: "https://s3.{{ item.region }}.amazonaws.com"
          access_key_id: "{{ item.access_key }}"
          access_key_secret: "{{ item.secret_key }}"
          region: "{{ item.region }}"
        EOF
      environment:
        KUBECONFIG: "{{ artifacts_dir }}/{{ cluster_name }}/kubeconfig"
      delegate_to: localhost
      no_log: true
      loop: "{{ cluster_s3_info }}"

    # =========================================================================
    # Create ACM Policy with operator install + LokiStack + FlowCollector
    # =========================================================================
    - name: Create NetObserv Policy
      shell: |
        oc apply -f - <<'POLICYEOF'
        apiVersion: policy.open-cluster-management.io/v1
        kind: Policy
        metadata:
          name: {{ policy_name }}
          namespace: {{ policy_namespace }}
          annotations:
            policy.open-cluster-management.io/categories: CM Configuration Management
            policy.open-cluster-management.io/standards: NIST SP 800-53
            policy.open-cluster-management.io/controls: CM-2 Baseline Configuration
        spec:
          disabled: false
          remediationAction: enforce
          policy-templates:
            # ================================================================
            # 1. Create required namespaces
            # ================================================================
            - objectDefinition:
                apiVersion: policy.open-cluster-management.io/v1
                kind: ConfigurationPolicy
                metadata:
                  name: netobserv-namespaces
                spec:
                  remediationAction: enforce
                  severity: low
                  object-templates:
                    - complianceType: musthave
                      objectDefinition:
                        apiVersion: v1
                        kind: Namespace
                        metadata:
                          name: openshift-operators-redhat
                    - complianceType: musthave
                      objectDefinition:
                        apiVersion: v1
                        kind: Namespace
                        metadata:
                          name: openshift-netobserv-operator
                    - complianceType: musthave
                      objectDefinition:
                        apiVersion: v1
                        kind: Namespace
                        metadata:
                          name: openshift-logging

            # ================================================================
            # 2. Loki OperatorPolicy
            # ================================================================
            - objectDefinition:
                apiVersion: policy.open-cluster-management.io/v1
                kind: ConfigurationPolicy
                metadata:
                  name: loki-operatorpolicy
                spec:
                  remediationAction: enforce
                  severity: high
                  object-templates:
                    - complianceType: musthave
                      objectDefinition:
                        apiVersion: policy.open-cluster-management.io/v1beta1
                        kind: OperatorPolicy
                        metadata:
                          name: loki-operator-install
                          namespace: openshift-operators-redhat
                        spec:
                          complianceType: musthave
                          complianceConfig:
                            catalogSourceUnhealthy: NonCompliant
                            deploymentsUnavailable: NonCompliant
                            upgradesAvailable: Compliant
                          remediationAction: enforce
                          removalBehavior:
                            clusterServiceVersions: Delete
                            customResourceDefinitions: Delete
                            operatorGroups: DeleteIfUnused
                            subscriptions: Delete
                          severity: critical
                          upgradeApproval: Automatic
                          subscription:
                            channel: {{ loki_channel }}
                            name: loki-operator
                            namespace: openshift-operators-redhat
                            source: redhat-operators
                            sourceNamespace: openshift-marketplace

            # ================================================================
            # 3. NetObserv OperatorPolicy
            # ================================================================
            - objectDefinition:
                apiVersion: policy.open-cluster-management.io/v1
                kind: ConfigurationPolicy
                metadata:
                  name: netobserv-operatorpolicy
                spec:
                  remediationAction: enforce
                  severity: high
                  object-templates:
                    - complianceType: musthave
                      objectDefinition:
                        apiVersion: policy.open-cluster-management.io/v1beta1
                        kind: OperatorPolicy
                        metadata:
                          name: netobserv-operator-install
                          namespace: openshift-netobserv-operator
                        spec:
                          complianceType: musthave
                          complianceConfig:
                            catalogSourceUnhealthy: NonCompliant
                            deploymentsUnavailable: NonCompliant
                            upgradesAvailable: Compliant
                          remediationAction: enforce
                          removalBehavior:
                            clusterServiceVersions: Delete
                            customResourceDefinitions: Delete
                            operatorGroups: DeleteIfUnused
                            subscriptions: Delete
                          severity: critical
                          upgradeApproval: Automatic
                          subscription:
                            channel: {{ netobserv_channel }}
                            name: netobserv-operator
                            namespace: openshift-netobserv-operator
                            source: redhat-operators
                            sourceNamespace: openshift-marketplace

            # ================================================================
            # 4. Loki S3 credentials secret (hub template injection)
            # ================================================================
            - extraDependencies:
                - apiVersion: policy.open-cluster-management.io/v1
                  kind: ConfigurationPolicy
                  name: loki-operatorpolicy
                  namespace: ""
                  compliance: Compliant
              objectDefinition:
                apiVersion: policy.open-cluster-management.io/v1
                kind: ConfigurationPolicy
                metadata:
                  name: loki-s3-credentials
                spec:
                  remediationAction: enforce
                  severity: high
                  object-templates:
                    - complianceType: musthave
                      objectDefinition:
                        apiVersion: v1
                        kind: Secret
                        metadata:
                          name: loki-s3-credentials
                          namespace: openshift-logging
                        type: Opaque
                        data:
                          bucketname: '{% raw %}{{hub fromSecret "netobserv-policy" (printf "netobserv-s3-creds-%s" .ManagedClusterName) "bucketname" hub}}{% endraw %}'
                          endpoint: '{% raw %}{{hub fromSecret "netobserv-policy" (printf "netobserv-s3-creds-%s" .ManagedClusterName) "endpoint" hub}}{% endraw %}'
                          access_key_id: '{% raw %}{{hub fromSecret "netobserv-policy" (printf "netobserv-s3-creds-%s" .ManagedClusterName) "access_key_id" hub}}{% endraw %}'
                          access_key_secret: '{% raw %}{{hub fromSecret "netobserv-policy" (printf "netobserv-s3-creds-%s" .ManagedClusterName) "access_key_secret" hub}}{% endraw %}'
                          region: '{% raw %}{{hub fromSecret "netobserv-policy" (printf "netobserv-s3-creds-%s" .ManagedClusterName) "region" hub}}{% endraw %}'

            # ================================================================
            # 5. LokiStack with S3 backend
            # ================================================================
            - extraDependencies:
                - apiVersion: policy.open-cluster-management.io/v1
                  kind: ConfigurationPolicy
                  name: loki-s3-credentials
                  namespace: ""
                  compliance: Compliant
              objectDefinition:
                apiVersion: policy.open-cluster-management.io/v1
                kind: ConfigurationPolicy
                metadata:
                  name: lokistack-config
                spec:
                  remediationAction: enforce
                  severity: high
                  object-templates:
                    - complianceType: musthave
                      objectDefinition:
                        apiVersion: loki.grafana.com/v1
                        kind: LokiStack
                        metadata:
                          name: loki
                          namespace: openshift-logging
                        spec:
                          size: 1x.small
                          storage:
                            schemas:
                            - version: v13
                              effectiveDate: "2024-10-18"
                            secret:
                              name: loki-s3-credentials
                              type: s3
                          tenants:
                            mode: openshift-network
                          limits:
                            global:
                              retention:
                                days: 7
                          rules:
                            enabled: false

            # ================================================================
            # 6. FlowCollector with LokiStack backend
            # ================================================================
            - extraDependencies:
                - apiVersion: policy.open-cluster-management.io/v1
                  kind: ConfigurationPolicy
                  name: lokistack-config
                  namespace: ""
                  compliance: Compliant
                - apiVersion: policy.open-cluster-management.io/v1
                  kind: ConfigurationPolicy
                  name: netobserv-operatorpolicy
                  namespace: ""
                  compliance: Compliant
              objectDefinition:
                apiVersion: policy.open-cluster-management.io/v1
                kind: ConfigurationPolicy
                metadata:
                  name: flowcollector-config
                spec:
                  remediationAction: enforce
                  severity: high
                  object-templates:
                    - complianceType: musthave
                      objectDefinition:
                        apiVersion: flows.netobserv.io/v1beta2
                        kind: FlowCollector
                        metadata:
                          name: cluster
                        spec:
                          namespace: netobserv
                          deploymentModel: Direct
                          agent:
                            type: eBPF
                            ebpf:
                              sampling: 50
                              logLevel: info
                              resources:
                                requests:
                                  cpu: 100m
                                  memory: 50Mi
                                limits:
                                  memory: 800Mi
                          loki:
                            enable: true
                            mode: LokiStack
                            lokiStack:
                              name: loki
                              namespace: openshift-logging
        POLICYEOF
      environment:
        KUBECONFIG: "{{ artifacts_dir }}/{{ cluster_name }}/kubeconfig"
      delegate_to: localhost

    # =========================================================================
    # Wait for policy compliance
    # =========================================================================
    - name: Wait for NetObserv policy to be Compliant
      shell: |
        oc get policy {{ policy_name }} -n {{ policy_namespace }} \
          -o jsonpath='{.status.compliant}'
      environment:
        KUBECONFIG: "{{ artifacts_dir }}/{{ cluster_name }}/kubeconfig"
      delegate_to: localhost
      register: policy_compliance
      until: policy_compliance.stdout == "Compliant"
      retries: 120
      delay: 15
      changed_when: false
      ignore_errors: true

    - name: Display policy compliance result
      debug:
        msg: |
          NetObserv Policy Status: {{ policy_compliance.stdout | default('Unknown') }}
          {% if policy_compliance.stdout == 'Compliant' %}
          All components deployed successfully:
          - Loki operator installed
          - NetObserv operator installed
          - S3 credentials secret created per cluster
          - LokiStack configured with S3 backend
          - FlowCollector collecting network flows via eBPF
          {% else %}
          Policy is not yet Compliant. Check status:
            oc describe policy {{ policy_name }} -n {{ policy_namespace }}
          {% endif %}

          Target clusters: {{ netobserv_clusters | join(', ') }}

          Verify on each cluster:
            oc get lokistack loki -n openshift-logging
            oc get flowcollector cluster
